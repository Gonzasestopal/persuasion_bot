# ðŸ¤– Persuasion Bot
An LLM-based chatbot that takes in messages from a user, processes them, and generates responses intended to defend itself or maintain its position during an ongoing conversation.

## ðŸ“œ Table of Contents
1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Entities](#entities)
4. [Tech Stack](#tech-stack)
5. [Getting Started](#getting-started)
6. [API Documentation](#api-documentation)
7. [Example Requests](#example-requests)
8. [Non Functional Requirements](#non-functional-requirements)
9. [Database Optimization](#database-optimization)
10. [Production Considerations](#produciton-considerations)

## Overview
This application challenges you to persuade a chatbot to adopt your point of view while it stands its ground on the initial stance.

Includes:
- Single endpoint to handle messages and responses.
- Conversation history capped at the 5 most recent user+bot pairs.

## Architecture
![Architecture Diagram](docs/architecture.png?v=2   )

- **Client**: Anyone consuming the API.
- **API**: REST API built with FastAPI.
- **Database**: ~~In-memory storage for dev/testing~~, PostgreSQL.
- **Cache**: Redis Cache to improve latency and enable rate limiting.

### Caching Strategy

We cache three things to improve latency, cut costs, and avoid duplicate work:

1. Idempotency Keys

    Prevents double processing when clients retry/double-send.

    Key: `idempotency:{request_uuid}` (TTL: 5â€“15 min).

2. Last Messages (Conversation History Cache)

    Stores last N messages of a conversation.

    Key: `conversation:{conversation_id}:history` (TTL: 30â€“60 min, reset on activity).

3. LLM Reply Cache

    Re-uses model reply for identical prompt/context.

    Key: `llm:{sha256(model+system_prompts+topic+side+last_K_msgs+user_msg+temperature)}` (TTL: 1â€“24h).

## Entities
![Entities](docs/entities.png)

Messages will contain ai prompts and responses.

- ```id```: id autogenerated
- ```conversation_id```: related conversation
- ```message```: message content
- ```role```: message owner (user, bot)
- ```timestamps```

Conversations will be used to link every message based on topic

- ```id```: id autogenerated
- ```side```: wheter bot will be against or in favor of (side, pro)
- ```topic```: subject of a conversation or discussion.
- ```timestamps```

## Tech Stack
- **Backend**: FastAPI (Python 3.9+)
- **Database**: ~~In-memory dict for dev/testing~~, PostgreSQL.
- **API Docs**: Swagger UI / ReDoc (auto-generated)
- **Containerization**: Docker

## Getting Started

### Prerequisites (Docker-first)
- Docker (required)
    - Follow Docker installation [instructions](https://docs.docker.com/engine/install/)
- GNU Make (required)
    - On Linux/macOS: preinstalled or install via package manager (sudo apt install make, brew install make)

    - On Windows: install via Chocolatey (choco install make) or MSYS2
- Python & pip (optional, for local-only dev/tests)
- PostgreSQL (optional, for local-only dev)

### Clone Repository
```bash
git clone https://github.com/gonzasestopal/persuasion_bot.git
cd persuasion_bot
```

### Environment
Copy .env.example to .env and adjust if needed:
```
POSTGRES_USER=app
POSTGRES_PASSWORD=app
POSTGRES_DB=app
DATABASE_URL=postgresql://app:app@db:5432/app
```

### Running the service
```
make run
```

### Running tests
```
make test
```

### Cleanup
```
make down   # stop Docker services if running (no-op if none exist)
make clean  # remove venv, caches, __pycache__
```

## API Documentation

Base URL:
- **Local:** `http://localhost:8000`

Authentication:
- None is required

### Messages
| Method | Endpoint                 | Description
|--------|--------------------------|-------------------------------------
| POST   | `/messages`              | Inserts a new message / Starts convo

## Example Requests

**Start a new conversation**
```http
POST /messages HTTP/1.1
Host: http://localhost:8000
Content-Type: application/json
```

```
{
    "conversation_id": null,
    "message": "Topic: Sports are one of the best ways to build discipline and strengthen community bonds. Side: PRO."
}
```
**Response 201**
```
{
    "conversation_id": "1",
    "message": [
        {
            "role": "user",
            "message": "Topic: Sports are one of the best ways to build discipline and strengthen community bonds. Side: PRO."
        },
        {
            "role": "bot",
            "message": "I will gladly take the PRO side. Sports are key in shaping discipline..."
        }
    ]
}
```

**Continue an existing conversation**
```http
POST /messages HTTP/1.1
Host: http://localhost:8000
Content-Type: application/json
```

```
{
    "conversation_id": 1,
    "message": "But sports also divide people"
}
```

**Response 200**
```
{
    "conversation_id": 1,
    "message": [
        {
            "role": "user",
            "message": "Topic: Sports are one of the best ways to build discipline and strengthen community bonds. Side: PRO."
        },
        {
            "role": "bot",
            "message": "I will gladly take the PRO side. Sports are key in shaping discipline..."
        },
        {
            "role": "user",
            "message": "But sports also divide people."
        },
        {
            "role": "bot",
            "message": "I formly believe that sports can unite and divide people in the same amount, only fanatism is the real problem."
        }
    ]
}
```

**Error Examples**
```
{ "detail": "message must not be empty." }                          # 422 Unprocessable Entity
{ "detail": "conversation_id must be null when starting a conversation" }  # 422 Unprocessable Entity
{ "detail": "conversation_id not found or expired" }                # 404 Not Found
{ "detail": "response generation timed out" }                       # 502 Bad Gateway
```

## Non Functional Requirements

**Latency**: Response < 30s (hard API cap). Internal timeout enforced at 25s.

**Scalability**: Caching layers reduce duplicate LLM calls and DB load.

**History Window**: Only the last 5 user+bot pairs are returned in responses.

**Fault Tolerance**: If timeout triggers, bot responds with a short fallback argument.

**Storage**: Conversations expire after 60 minutes of inactivity.

## Database Optimization

- **conversations (expires_at)**
  - Speeds up lookups for active conversations (`expires_at > NOW()`)
  - Used in cleanup job to quickly delete expired rows

- **messages (conversation_id, created_at)**
  - Optimizes retrieval of the last N messages for a conversation
  - Maintains ordering by creation time for fast sequential reads

## Production Considerations

For simplicity, expired conversations will not be physically deleted from the database in this implementation. In a production system, you would typically run a periodic cleanup job to purge expired rows.
