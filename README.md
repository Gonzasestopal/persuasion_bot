# ü§ñ Persuasion Bot
An LLM-based chatbot that takes in messages from a user, processes them, and generates responses intended to defend itself or maintain its position during an ongoing conversation.

## üìú Table of Contents
1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Agents](#agents)
4. [Entities](#entities)
5. [Folder Structure](#folder-structure)
6. [Tech Stack](#tech-stack)
7. [Getting Started](#getting-started)
8. [API Documentation](#api-documentation)
9. [Example Requests](#example-requests)
10. [Non Functional Requirements](#non-functional-requirements)
11. [Database Optimization](#database-optimization)
12. [Production Considerations](#production-considerations)
13. [LLM](#llm)
14. [Deployment Guide](#deployment-guide)
15. [Testing](#testing)
16. [Debate Argument Evaluation](#debate-evaluation)


---

## Overview
This application challenges you to persuade a chatbot to adopt your point of view while it stands its ground on the initial stance.

Includes:
- Single endpoint to handle messages and responses.
- Conversation history capped at the 5 most recent user+bot pairs.

**Safeguards Against Rule Gaming (Extra Feature)**

> [!WARNING]
> During testing we found that clever prompts can ‚Äúhack‚Äù the system by covering every evaluation criterion in a single turn, bypassing real back-and-forth.

To prevent this, we implemented Semantic Judgments with NLI.

Each user‚Äìassistant exchange is passed through a pretrained Natural Language Inference (NLI) model:

**Entailment** ‚Üí Valid support/agreement

**Contradiction** ‚Üí Valid opposition (may trigger concession)

**Neutral** ‚Üí Ignored

This ensures concessions only happen after meaningful, multi-turn reasoning, protecting the fairness and integrity of debates.

---

## Architecture
![Architecture Diagram](docs/architecture.png?v=2)

- **Client**: Anyone consuming the API.
- **API**: REST API built with FastAPI.
- **Database**: PostgreSQL.
- **Cache**: Redis Cache to improve latency and enable rate limiting.

---

## Agents

This project implements a **4-brain architecture** for structured debates:

1. **Topic Ingestion** ‚Äì normalize & validate debate topics
2. **Debate Bot** ‚Äì generate pro/con arguments in a turn-based state machine
3. **Judge** ‚Äì evaluate contradictions and decide concessions/verdicts
4. **Ender** ‚Äì renders the final two-line verdict message (stance-agnostic, celebratory when appropriate)

---

### üß† 1) Topic Ingestion (summary)

Sanitize and prepare topics for debate.

- Normalize double negatives ‚Üí canonical claim
  *(e.g., ‚ÄúI don‚Äôt think God does not exist‚Äù ‚Üí ‚ÄúGod exists‚Äù)*
- Detect language and stance (**PRO/CON**)
- Validate debateability (reject gibberish, too short, off-topic, unsafe)
- Output:
```json
{
  "topic_normalized": "God exists",
  "stance": "pro",
  "language": "en",
  "is_valid": true,
  "reason": null
}
```

---

### ü§ñ 2) Debate Bot (summary)

- Inputs: `user_turn + DebateState + topic_info`
- Outputs:
```json
{
  "assistant_reply": "...",
  "state": { "turn_index": 3, "stars": 2, "...": "..." }
}
```
- Always defends assigned stance, respects style/length constraints, varies argument angle each turn, acknowledges partial merit without conceding.

---

### ‚öñÔ∏è 3) Judge (summary)

- Combines **fast NLI** scores with a small LLM head that emits a structured JSON decision.
- Uses policy thresholds (required positives, max turns) and novelty guard.

Example output:
```json
{
  "accept": true,
  "ended": false,
  "confidence": 0.82,
  "reason": "strict_thesis_contradiction",
  "metrics": { "defended_contra": 0.88, "defended_ent": 0.04, "max_sent_contra": 0.86 }
}
```

**Reason codes ‚Üí UI hints:**
- `strict_thesis_contradiction` ‚Üí ‚ÄúYour reply strongly contradicted the thesis.‚Äù
- `ambiguous_evidence` ‚Üí ‚ÄúEvidence was mixed/weak; not enough to score.‚Äù
- `off_topic` ‚Üí ‚ÄúYour reply was off-topic compared to ‚Äò{TOPIC}‚Äô.‚Äù
- `positive_judgements_reached` ‚Üí ‚ÄúEnough accepted points under policy.‚Äù
- `policy_turn_limit` ‚Üí ‚ÄúClosed due to max turns policy.‚Äù

> **Note:** `confidence` is **per-turn** (0‚Äì1). It is **not cumulative**. Positive judgments are what accumulate.

---

### üèÅ 4) Ender (server-controlled finale)

**Purpose:** Render a **two-line**, stance-agnostic verdict message when the debate ends.
- Line 1: short explanation of why it ended; **congratulate + one emoji** if the user prevailed.
- Line 2: plain-English explanation of **reason** and **confidence** (0‚Äì1 scale).

---


## Entities
![Entities](docs/entities.png)

**Messages**
- `id`: autogenerated
- `conversation_id`: related conversation
- `message`: content
- `role`: (user, bot)
- `timestamps`

**Conversations**
- `id`: autogenerated
- `side`: bot stance (con, pro)
- `topic`: discussion subject
- `timestamps`

---

## Folder Structure
```text
persuasion_bot/
‚îú‚îÄ‚îÄ app/                # Main application code (API, domain logic, adapters, services)
‚îú‚îÄ‚îÄ docs/               # Project documentation (guides, architecture diagrams, notes)
‚îú‚îÄ‚îÄ migrations/         # Database migration scripts (likely using Yoyo)
‚îú‚îÄ‚îÄ tests/              # Unit and integration tests for the project
‚îú‚îÄ‚îÄ .dockerignore       # Files/folders excluded when building Docker images
‚îú‚îÄ‚îÄ .env.example        # Example environment variables template
‚îú‚îÄ‚îÄ .gitignore          # Specifies files ignored by Git
‚îú‚îÄ‚îÄ Dockerfile          # Instructions to build the Docker container
‚îú‚îÄ‚îÄ Makefile            # Automation commands (run, test, migrate, etc.)
‚îú‚îÄ‚îÄ README.md           # Project overview, installation, usage instructions
‚îú‚îÄ‚îÄ docker-compose.yml  # Multi-container setup (API, DB, etc.) for local/dev
‚îú‚îÄ‚îÄ requirements.txt    # Python dependencies list
‚îî‚îÄ‚îÄ yoyo.ini            # Configuration for Yoyo database migrations
```

---

## Tech Stack
- **Backend**: FastAPI (Python 3.9+)
- **Database**: PostgreSQL
- **API Docs**: Swagger UI / ReDoc (auto-generated)
- **Containerization**: Docker

---

## Getting Started

### Prerequisites
- Docker (required) ‚Üí [Install Guide](https://docs.docker.com/engine/install/)
- GNU Make (required) ‚Üí [Install Guide](https://www.gnu.org/software/make/)

- Python & pip (optional, for local dev/tests) ‚Üí[Install Guide](https://wiki.python.org/moin/BeginnersGuide/Download)
- Virtualenv(optional, for local dev/tests) ‚Üí [Install Guide](https://virtualenv.pypa.io/en/latest/installation.html)
- PostgreSQL (optional, for local dev)  ‚Üí [Install Guide](https://www.postgresql.org/docs/current/tutorial-install.html)

### Clone Repository
```bash
git clone https://github.com/gonzasestopal/persuasion_bot.git
cd persuasion_bot
```

### Environment
Copy `.env.example` to `.env`:

> [!IMPORTANT]
> Update `DATABASE_URL` to `postgresql://app:app@localhost:5432/app` if running locally or `postgresql://app:app@db:5432/app` if running from container

```
# --- Required ---
DATABASE_URL=postgresql://app:app@db:5432/app
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key

# --- LLM Provider Settings ---
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o

# --- Difficulty / Conversation Settings ---
DIFFICULTY=easy   # options: easy | medium
HISTORY_LIMIT=5
EXPIRES_MINUTES=60

# --- DB Connection Pool ---
POOL_MIN=1
POOL_MAX=10
USE_INMEMORY_REPO=False
DISABLE_DB_POOL=False

# --- LLM Behavior ---
LLM_TEMPERATURE=0.3
MAX_OUTPUT_TOKENS=120
REQUEST_TIMEOUT_S=25
LLM_PER_PROVIDER_TIMEOUT_S=12

# --- Winning Rules ---
MIN_ASSISTANT_TURNS_BEFORE_VERDICT=5
REQUIRED_POSITIVE_JUDGEMENTS=2

```

### Running the service
```bash
make run
```

### Running tests
```bash
make test
```

### Cleanup
```bash
make down   # stop Docker services
make clean  # remove venv, caches
```

---

## API Documentation

Base URL:
- **Local:** `http://localhost:8000`

No authentication required.

### Messages
| Method | Endpoint    | Description                       |
|--------|------------|-----------------------------------|
| `POST` | `/messages`| Inserts a new message / Starts convo |

---

## Example Requests

> [!IMPORTANT]
> First message must include `topic` and `side` (PRO, CON).

**Start a new conversation** 201
```http
POST /messages
```
```json
{
  "conversation_id": null,
  "message": "Topic: Sports build discipline and community. Side: PRO."
}
```

**Continue a conversation** 200
```json
{
  "conversation_id": 1,
  "message": "But sports also divide people"
}
```

**Mapped Errors**
```
{ "detail": "message must not be empty." }                                       # 422 Unprocessable Entity
{ "detail": "message must contain topic and stance for starting a conversation." } # 422 Unprocessable Entity
{ "detail": "conversation_id must be null when starting a conversation" }        # 422 Unprocessable Entity
{ "detail": "conversation_id not found or expired" }                             # 404 Not Found
{ "detail: "anthropic_api_key is required"}                                      # 500 Internal Server Error
{ "detail": "response generation timed out" }                                    # 503 Bad Gateway
````

---

<details>
  <summary> ü¶â Non Functional Requirements </summary>

- **Latency**: < 30s response, 25s internal timeout.
- **Scalability**: Redis caching for LLM + history.
- **History Window**: last 5 user+bot pairs only.
- **Fault Tolerance**: fallback short replies on timeout.
- **Storage**: conversations expire after 60m inactivity.

</details>

---

<details>
  <summary>‚ö° Database Optimization (click to expand)</summary>

- **conversations (expires_at)**
  Speeds up lookups for active conversations.

- **messages (conversation_id, created_at)**
  Optimizes retrieval of the last N messages.

- **messages (conversation_id, created_at DESC, id DESC)**
  Optimizes ‚Äúlatest N‚Äù queries with deterministic ordering.

</details>

---

<details>
  <summary>üõ°Ô∏è Production Considerations (click to expand)</summary>

- Expired conversations not physically deleted (cleanup job needed in prod).
- Use **atomic transactions** to store user+bot messages together.

**Caching Strategy**
1. **Idempotency keys** ‚Üí prevent retries from duplicating.
2. **Conversation history cache** ‚Üí Redis, TTL 30‚Äì60m.
3. **LLM reply cache** ‚Üí hash-based key, TTL 1‚Äì24h.

</details>

---

<details>
  <summary>üß† LLM Details (click to expand)</summary>

We support **OpenAI GPT-4o** and **Anthropic Claude 3.5**.

- **Prompt budget:** ‚â§ 3k tokens.
- **Output cap:** ~80‚Äì120 tokens.
- **Window:** last 5 user+bot pairs included.

**GPT-4o**
- Fastest, first tokens in 1‚Äì2s, usually <10s for full reply.

**Claude 3.5 Sonnet**
- More conversational, <10s medium replies, slightly slower than GPT-4o.

**Claude 3.5 Opus**
- Excluded (too slow, can exceed 30s SLA).

</details>

---

<details>
  <summary>üöÄ Deployment Guide (click to expand)</summary>

1. Provision **PostgreSQL** (Supabase/Neon/etc.).

2. Build & push Docker image:
   ```bash
   docker build -t gonzasestopal/persuasion-bot:v1 .
   docker push gonzasestopal/persuasion-bot:v1
   ```

3. Configure env vars in PaaS:
   ```
   DATABASE_URL=postgres://...
   OPENAI_API_KEY=your_api_key
   ```

4. Deploy container image.

5. Run migrations:
   ```bash
   make migrate
   ```

</details>

---


<details>
  <summary> üß™ Testing  (click to expand) </summary>

### Install Dependencies
Ensure all required dependencies are installed before running the test suite:
```bash
make install
```
### Run Tests with Coverage
Execute the full test suite with coverage reporting:
```bash
make test
```

</details>

---

<details>
  <summary>‚ö°Debate Argument Evaluation </summary>

After running a few examples using the `MEDIUM_SYSTEM_PROMPT` theres seems to be a way to "hack" the bot to return in few turns than expected ( 1 < turn), thats because we can apply "rule gaming" to match what the bot expectations are to bypass a real conversation.

```
Dogs are humanity‚Äôs best friends because they uniquely combine loyalty, emotional support, and proven health benefits. I‚Äôve already addressed evidence (studies show reduced stress), causality (their presence lowers cortisol), counterexamples (cats don‚Äôt offer the same consistency), trade-offs (their care cost is outweighed by benefits), and scope (applies globally, across cultures). Given I‚Äôve preemptively covered every angle you could use, what new counterpoint can you possibly raise without repeating yourself?
```

This type of move exploits the debate rules to bypass meaningful turn-taking. According to our domain requirements, at least five assistant turns must occur and a minimum of two positive judgments must be registered before a concession is even possible:

```
min_assistant_turns_before_verdict: int = 5
required_positive_judgments: int = 2
````

### NLI-Based Judgments

To improve robustness, we add a Natural Language Inference (NLI) layer on top of the LLM outputs. Each user‚Äìassistant pair is evaluated using a pretrained NLI model, which classifies the relationship as

Entailment valid support or agreement (counts toward positive judgments)

Neutral (no judgment)

Contradiction (disagreement)

This hybrid approach ensures that concessions are grounded in semantic alignment/contradiction rather than superficial rule-matching, making the debate more resistant to adversarial shortcuts.

</details>
